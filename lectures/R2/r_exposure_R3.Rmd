---
title: "CSSS508, Week 3"
subtitle: "Manipulating and Summarizing Data"
author: "Chuck Lanfear"
date: "Oct 9, 2019<br>Updated: `r gsub(' 0', ' ', format(Sys.Date(), format='%b %d, %Y'))`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: tomorrow-night-bright
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["center","top"]
---

```{r setup, include=FALSE, purl=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(comment = "##")
library(ggplot2)
```

```{r xaringan-themer, include = FALSE, purl=FALSE}
library(xaringanthemer)
source("../csss508css.R")
```


# Death to Spreadsheets

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 90)
```

Today we'll talk more about `dplyr`: a package that does in R just about any calculation you've tried to do in Excel, but more *transparently*, *reproducibly*, and *safely*. 

Don't be the next sad research assistant who makes headlines with an Excel error ([Reinhart & Rogoff, 2010](http://www.bloomberg.com/news/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history))

---
class: inverse

# Modifying Data Frames with `dplyr`


---
# But First, Pipes (%>%)

`dplyr` uses the [`magrittr`](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html) forward pipe operator, usually called simply a **pipe**. We write pipes like `%>%` (`Ctrl+Shift+M`).

--

Pipes take the object on the *left* and apply the function on the *right*: `x %>% f(y) = f(x, y)`. Read out loud: "and then..."

--

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(gapminder)
gapminder %>% filter(country == "Canada") %>% head(2)
```

--

Pipes save us typing, make code readable, and allow chaining like above, so we use them *all the time* when manipulating data frames.

---

# Using Pipes


Pipes are clearer to read when you have each function on a separate line (inconsistent in these slides because of space constraints).

--

```{r, eval=FALSE}
take_these_data %>%
    do_first_thing(with = this_value) %>%
    do_next_thing(using = that_value) %>% ...
```

--

Stuff to the left of the pipe is passed to the *first argument* of the function on the right. Other arguments go on the right in the function. 

--

If you ever find yourself piping a function where data are not the first argument, use `.` in the data argument instead.
```{r, eval=FALSE}
yugoslavia %>% lm(pop ~ year, data = .)
```

---
# Pipe Assignment

When creating a new object from the output of piped functions, place the assignment operator at the beginning.

```{r, eval=FALSE}
lm_pop_year <- gapminder %>% 
  filter(continent == "Americas") %>%
  lm(pop ~ year, data = .)
```

No matter how long the chain of functions is, assignment is always done at the top.<sup>1</sup>

.footnote[[1] Note this is just a stylistic convention: If you prefer, you *can* do assignment at the end of the chain.]

---
# Filtering Rows (subsetting)

Recall last week we used the `filter()` command to subset data like so:
```{r}
Canada <- gapminder %>%
    filter(country == "Canada")
```

Excel analogue: Filter!

![Excel's filter](http://content.gcflearnfree.org/topics/143/ex07_filter.gif)

---
# Another Operator: `%in%`

Common use case: Filter rows to things in some *set*.

We can use `%in%` like `==` but for matching *any element* in the vector on its right<sup>1</sup>. 

```{r}
former_yugoslavia <- c("Bosnia and Herzegovina", "Croatia", 
              "Macedonia", "Montenegro", "Serbia", "Slovenia")
yugoslavia <- gapminder %>% filter(country %in% former_yugoslavia)
tail(yugoslavia, 2)
```

.footnote[[1] The `c()` function is how we make **vectors** in R, which are an important data type.]

---
## `distinct()`

You can see all the *unique values* in your data for combinations of columns using `distinct()`:

```{r}
gapminder %>% distinct(continent, year)
```

---
### `distinct()` drops unused variables!


Note that the default behavior of `distinct()` is to drop all unspecified columns. If you want to get distinct rows by certain variables without dropping the others, use `distinct(.keep_all=TRUE)`:

```{r}
gapminder %>% distinct(continent, year, .keep_all=TRUE)
```

---
# Sampling Rows: `sample_n()`

We can also filter *at random* to work with a smaller dataset using `sample_n()` or `sample_frac()`.

```{r}
set.seed(413) # makes random numbers repeatable #<<
yugoslavia %>% sample_n(size = 6, replace = FALSE)
```

.footnote[Use `set.seed()` to make all random numbers in a file come up *exactly the same* each time it is run. Read *Details* in `?set.seed` if you like your brain to hurt.]

---
## Sorting: `arrange()`

Along with filtering the data to see certain rows, we might want to sort it:

```{r}
yugoslavia %>% arrange(year, desc(pop))
```

The data are sorted by ascending `year` and descending `pop`.

---
## Keeping Columns: `select()`

Not only can we limit rows, but we can include specific columns (and put them in the order listed) using `select()`. 

```{r}
yugoslavia %>% select(country, year, pop) %>% head(4)
```

---
## Dropping Columns: `select()`


We can instead drop only specific columns with `select()` using `-` signs:

```{r}
yugoslavia %>% select(-continent, -pop, -lifeExp) %>% head(4)
```

---
## Helper Functions for `select()`


`select()` has a variety of helper functions like `starts_with()`, `ends_with()`, and `contains()`, or can be given a range of continguous columns `startvar:endvar`. See `?select` for details.

These are very useful if you have a "wide" data frame with column names following a pattern or ordering. 

![DYS Data Example](http://clanfear.github.io/CSSS508/Lectures/Week3/img/dys_vars.PNG)

```{r, eval=FALSE}
DYS %>% select(starts_with("married"))
DYS %>% select(ends_with("18"))
```

---
## Renaming Columns with `select()`


We can rename columns using `select()`, but that drops everything that isn't mentioned:

```{r}
yugoslavia %>%
    select(Life_Expectancy = lifeExp) %>%
    head(4)
```

---
### Safer: Rename Columns with `rename()`


`rename()` renames variables using the same syntax as `select()` without dropping unmentioned variables.

```{r}
yugoslavia %>%
    select(country, year, lifeExp) %>%
    rename(Life_Expectancy = lifeExp) %>%
    head(4)
```

---
## Column Naming Practices

* *Good* column names will be self-describing. Don't use inscrutable abbreviations to save typing. RStudio's autocompleting functions take away the pain of long variable names: Hit `TAB` while writing code to autocomplete.

--

* *Valid* "naked" column names can contain upper or lowercase letters, numbers, periods, and underscores. They must start with a letter or period and not be a special reserved word (e.g. `TRUE`, `if`).

--

* Names are case-sensitive: `Year` and `year` are not the same thing!

--

* You can include spaces or use reserved words if you put backticks around the name. Spaces can be worth including when preparing data for `ggplot2` or `pander` since you don't have to rename axes or table headings.

---

## Column Name with Space Example

```{r}
library(pander)
yugoslavia %>% filter(country == "Serbia") %>%
    select(year, lifeExp) %>%
    rename(Year = year, `Life Expectancy` = lifeExp) %>%
    head(5) %>%
    pander(style = "rmarkdown", caption = "Serbian life expectancy")
```

---
## Create New Columns: `mutate()`

In `dplyr`, you can add new columns to a data frame using `mutate()`.

--


```{r}
yugoslavia %>% filter(country == "Serbia") %>%
    select(year, pop, lifeExp) %>%
    mutate(pop_million = pop / 1000000,
           life_exp_past_40 = lifeExp - 40) %>%
    head(5)
```

Note you can create multiple variables in a single `mutate()` call by separating the expressions with commas.

---
# `ifelse()`


A common function used in `mutate()` (and in general in R programming) is `ifelse()`. It returns a vector of values depending on a logical test.

```{r, eval=FALSE}
ifelse(test = x==y, yes = first_value , no = second_value)
```

Output from `ifelse()` if `x==y` is...
* `TRUE`: `first_value` - the value for `yes =`

* `FALSE`: `second_value` - the value for `no = `

* `NA`: `NA` - because you can't test for NA with an equality!

--

For example:

```{r}
example <- c(1, 0, NA, -2)
ifelse(example > 0, "Positive", "Not Positive")
```

---
# `ifelse()` Example


```{r}
yugoslavia %>% mutate(short_country = 
                 ifelse(country == "Bosnia and Herzegovina", 
                        "B and H", as.character(country))) %>%
    select(short_country, year, pop) %>%
    arrange(year, short_country) %>%
    head(3)
```

Read this as "For each row, if country equals 'Bosnia and Herzegovina, make `short_country` equal to 'B and H', otherwise make it equal to that row's value of `country`."

This is a simple way to change some values but not others!

---
# `recode()`


`recode()` is another useful function to use inside `mutate()`. Use `recode()` to change specific values to other values, particularly with factors. You can change multiple values at the same time. Note if a value has spaces in it, you'll need to put it in backticks!

```{r}
yugoslavia %>% 
  mutate(country = recode(country, 
                        `Bosnia and Herzegovina`="B and H", #<<
                        Montenegro="M")) %>% 
  distinct(country)
```

---
# `case_when()`

`case_when()` performs multiple `ifelse()` operations at the same time. `case_when()` allows you to create a new variable with values based on multiple logical statements. This is useful for making categorical variables or variables from combinations of other variables.

.smallish[
```{r}
gapminder %>% 
  mutate(gdpPercap_ordinal = 
    case_when(
      gdpPercap <  700 ~ "low",
      gdpPercap >= 700 & gdpPercap < 800 ~ "moderate",
      TRUE ~ "high" )) %>% # Value when all other statements are FALSE
  slice(6:9) # get rows 6 through 9
```
]

---

# `pull()`

Sometimes you want to extract a single column from a data frame as a *vector* (or single value). 

`pull()` *pulls* a column of a data frame out as a vector.

```{r}
gapminder %>% pull(lifeExp) %>% head(4)
```

```{r}
gapminder %>% select(lifeExp) %>% head(4)
```

.pull-right[.footnote[Note the difference between these two operations: The second yields only one column but is still a data frame.]]
---

# In-Line `pull()`

`pull()` is particularly useful when you want to use a vector-only command in a `dplyr` chain of functions (say, in an in-line expression).

This in-line code...

<p><code>The average life expectancy in Afghanistan from 1952 to 2007 was </code><code  class="r">`</code><code class="r">r gapminder %>% filter(country=="Afghanistan") %>% pull(lifeExp) %>% mean() %>% round(1)`</code><code> years.</code></p>

... will produce this output:

The average life expectancy in Afghanistan from 1952 to 2007 was `r gapminder %>% filter(country=="Afghanistan") %>% pull(lifeExp) %>% mean() %>% round(1)` years.

`mean()` can only take a *vector* input, not a dataframe, so this won't work with `select(lifeExp)` instead of `pull(lifeExp)`.

---
class: inverse

# Summarizing with `dplyr`

---
## General Aggregation: `summarize()`

`summarize()` takes your column(s) of data and computes something using every row:

* Count how many rows there are
* Calculate the mean
* Compute the sum
* Obtain a minimum or maximum value

You can use any function in `summarize()` that aggregates multiple values into a single value (like `sd()`, `mean()`, or `max()`).

---
# `summarize()` Example

For the year 1982, let's get the number of observations, total population, mean life expectancy, and range of life expectancy for former Yugoslavian countries.

```{r}
yugoslavia %>%
    filter(year == 1982) %>%
    summarize(n_obs          = n(),
              total_pop      = sum(pop),
              mean_life_exp  = mean(lifeExp),
              range_life_exp = max(lifeExp) - min(lifeExp))
```

These new variables are calculated using *all of the rows* in `yugoslavia`

---
# Avoiding Repetition: 

### `summarize_at()`


Maybe you need to calculate the mean and standard deviation of a bunch of columns. With `summarize_at()`, put the variables to compute over first in `vars()` (like `select()` syntax) and put the functions to use in a `list()` after.

```{r}
yugoslavia %>%
    filter(year == 1982) %>%
    summarize_at(vars(lifeExp, pop), list(mean = mean, sd = sd))
```

You can also use `purrr` syntax (e.g. `~ mean(.)`) and it will automatically name the outputs.

---
# Avoiding Repetition

### Other functions:


There are additional `dplyr` functions similar to `summarize_at()`:

* `summarize_all()` and `mutate_all()` summarize / mutate *all* variables sent to them in the same way. For instance, getting the mean and standard deviation of an entire dataframe (using `purrr` style functions):

```{r, eval=FALSE}
dataframe %>% summarize_all(list(~mean(.), ~sd(.)))
```

* `summarize_if()` and `mutate_if()` summarize / mutate all variables that satisfy some logical condition. For instance, summarizing every numeric column in a dataframe at once:

```{r, eval=FALSE}
dataframe %>% summarize_if(is.numeric, list(~mean(.), ~sd(.)))
```

You can use all of these to avoid typing out the same code repeatedly!

---
# `group_by()`


The special function `group_by()` changes how functions operate on the data, most importantly `summarize()`.

Functions after `group_by()` are computed *within each group* as defined by variables given, rather than over all rows at once. Typically the variables you group by will be integers, factors, or characters, and not continuous real values.

Excel analogue: pivot tables

.image-50[![Pivot table](http://www.excel-easy.com/data-analysis/images/pivot-tables/two-dimensional-pivot-table.png)]

---
# `group_by()` example


```{r}
yugoslavia %>%
  group_by(year) %>% #<<
    summarize(num_countries     = n_distinct(country),
              total_pop         = sum(pop),
              total_gdp_per_cap = sum(pop*gdpPercap)/total_pop) %>%
    head(5)
```

Because we did `group_by()` with `year` then used `summarize()`, we get *one row per value of `year`*!

---
## Window Functions

Grouping can also be used with `mutate()` or `filter()` to give rank orders within a group, lagged values, and cumulative sums. You can read more about window functions in this [vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html).

```{r}
yugoslavia %>% 
  select(country, year, pop) %>%
  filter(year >= 2002) %>% 
  group_by(country) %>%
  mutate(lag_pop = lag(pop, order_by = year),
         pop_chg = pop - lag_pop) %>%
  head(4)
```

---
class: inverse
##Joining (Merging) Data Frames

---
## When Do We Need to Join Tables?

* Want to make columns using criteria too complicated for `ifelse()` or `case_when()`

  + We can work with small sets of variables then combine them back together.

* Combine data stored in separate data sets: e.g. UW registrar data with police stop records.

  + Often large surveys are broken into different data sets for each level (e.g. household, individual, neighborhood)

---
## Joining in Concept

We need to think about the following when we want to merge data frames `A` and `B`:

* Which *rows* are we keeping from each data frame?

* Which *columns* are we keeping from each data frame?

* Which variables determine whether rows *match*?

---
## Join Types: Rows and columns kept

There are many types of joins<sup>1</sup>...

* `A %>% left_join(B)`: keep all rows from `A`, matched with `B` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% right_join(B)`: keep all rows from `B`, matched with `A` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% inner_join(B)`: keep only rows from `A` and `B` that match, keep columns from both `A` and `B`

* `A %>% full_join(B)`: keep all rows from both `A` and `B`, matched wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% semi_join(B)`: keep rows from `A` that match rows in `B`, keep columns from only `A`

* `A %>% anti_join(B)`: keep rows from `A` that *don't* match a row in `B`, keep columns from only `A`

.pull-right[.footnote[[1] Usually `left_join()` does the job.]]

---
## Matching Criteria

We say rows should *match* because they have some columns containing the same value. We list these in a `by = ` argument to the join.

Matching Behavior:

* No `by`: Match using all variables in `A` and `B` that have identical names

--

* `by = c("var1", "var2", "var3")`: Match on identical values of `var1`, `var2`, and `var3` in both `A` and `B`

--

* `by = c("Avar1" = "Bvar1", "Avar2" = "Bvar2")`: Match identical values of `Avar1` variable in `A` to `Bvar1` variable in `B`, and `Avar2` variable in `A` to `Bvar2` variable in `B`

Note: If there are multiple matches, you'll get *one row for each possible combination* (except with `semi_join()` and `anti_join()`).

Need to get more complicated? Break it into multiple operations.

---
## `nycflights13` Data

We'll use data in the [`nycflights13` package](https://cran.r-project.org/web/packages/nycflights13/nycflights13.pdf). Install and load it:
```{r}
# install.packages("nycflights13") # Uncomment to run
library(nycflights13)
```

It includes five dataframes, some of which contain missing data (`NA`):

* `flights`: flights leaving JFK, LGA, or EWR in 2013
* `airlines`: airline abbreviations
* `airports`: airport metadata
* `planes`: airplane metadata
* `weather`: hourly weather data for JFK, LGA, and EWR

Note these are *separate data frames*, each needing to be *loaded separately*:

```{r, eval=FALSE}
data(flights)
data(airlines)
data(airports)
# and so on...
```

---
## Join Example #1

Who manufactures the planes that flew to Seattle?
```{r}
flights %>% filter(dest == "SEA") %>% select(tailnum) %>%
    left_join(planes %>% select(tailnum, manufacturer), #<<
              by = "tailnum") %>%
    count(manufacturer) %>% # Count observations by manufacturer
    arrange(desc(n)) # Arrange data descending by count
```

Note you can perform operations on the data inside functions such as `left_join()` and the *output* will be used by the function.

---
## Join Example #2

Which airlines had the most flights to Seattle from NYC?
```{r}
flights %>% filter(dest == "SEA") %>% 
    select(carrier) %>%
    left_join(airlines, by = "carrier") %>%
    group_by(name) %>% 
    tally() %>% #<<
    arrange(desc(n))
```

`tally()` is a shortcut for `summarize(n(.))`: It creates a variable `n` equal to the number of rows in each group.

---
## Join Example #3

Is there a relationship between departure delays and wind gusts?

```{r, warning=FALSE, message=FALSE, eval=FALSE}
library(ggplot2)
flights %>% 
    select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, 
           by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    # removing rows with missing values
    filter(!is.na(dep_delay) & !is.na(wind_gust)) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_point() + 
      geom_smooth()
```

Because the data are the first argument for `ggplot()`, we can pipe them straight into a plot.

---
## Wind Gusts and Delays

```{r, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE, fig.height=4, dev='png', dpi=600}
flights %>% select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    # removing rows with missing values
    filter(!is.na(dep_delay) & !is.na(wind_gust)) %>%
    # Funky 1200 mph observations were dropped so I make new ones!
    mutate(wind_gust = if_else(row_number() %in% c(1,2,3), 1200, wind_gust)) %>%
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_point() + geom_smooth()
```

Check out those 1200 mph winds!<sup>1</sup>

.footnote[[1] These observations appear to have been fixed in the current data.]

---
## Redo After Removing Extreme Outliers, Just Trend

.small[
```{r, warning=FALSE, message=FALSE, eval=FALSE}
flights %>% 
    select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    filter(!is.na(dep_delay) & !is.na(wind_gust) & wind_gust < 250) %>% #<<
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_smooth() + 
      theme_bw(base_size = 16) +
      xlab("Wind gusts in departure hour (mph)") +
      ylab("Average departure delay (minutes)")
```
]

I removed `geom_point()` to focus on the mean trend produced by `geom_smooth()`.

---
## Wind Gusts and Delays: Mean Trend

```{r, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE, fig.height=4, dev='svg'}
flights %>% 
    select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    filter(!is.na(dep_delay) & !is.na(wind_gust) & wind_gust < 250) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_smooth() + 
      theme_bw(base_size = 16) +
      xlab("Wind gusts in departure hour (mph)") +
      ylab("Average departure delay (minutes)")
```

---
## Tinkering Suggestions

Some possible questions to investigate:

* What are the names of the most common destination airports?
* Which airlines fly from NYC to your home city?
* Is there a relationship between departure delays and precipitation?
* Use the time zone data in `airports` to convert flight arrival times to NYC local time.
    + What is the distribution of arrival times for flights leaving NYC over a 24 hour period?
    + Are especially late or early arrivals particular to some regions or airlines?

**Warning:** `flights` has `r nrow(flights)` rows, so if you do a sloppy join, you can end up with **many** matches per observation and have the data *explode* in size.

---
class: inverse

# Homework 3

Pick something to look at in the `nycflights13` data and write up a .Rmd file showing your investigation. Upload both the .Rmd file and the .html file to Canvas. You must use at least once: `mutate()`, `summarize()`, `group_by()`, and any join. *Include at least one nicely formatted plot (`ggplot2`) and one table (`pander`)*. In plots and tables, use "nice" variable names (try out spaces!) and rounded values (<= 3 digits).

This time, *include all your code in your output document* (`echo=TRUE`), using comments and line breaks separating commands so that it is clear to a peer what you are doing (or trying to do!). You must write up your observations briefly in words as well.  

Note: If you want to see the `nycflights13` dataframes in the environment, you will need to load *each one*: `airlines`, `airports`, `flights`, `planes`, and `weather` (e.g. `data(flights)`).

## DUE: 11:59 PM, October 15th

---

# R Data Types

So far we've been manipulating data frames, making visuals, and summarizing. This got you pretty far!

Now we get more in the weeds of programming.

Today is all about *types of data* in R.

---
# Up Until Now

A data frame is really a **list** of **vectors**, where each vector is a column of the same length (number of rows).

But data frames are not the only object we want to have in R (e.g. linear regression output).

We need to learn about **vectors**, **matrices**, and **lists** to do additional things we can't express with `dplyr` syntax.

---
class: inverse
# Vectors

---
# Making Vectors

In R, we call a set of values of the same type a **vector**. We can create vectors using the `c()` function ("c" for **c**ombine or **c**oncatenate).

```{r}
c(1, 3, 7, -0.5)
```

--

Vectors have one dimension: **length**
```{r}
length(c(1, 3, 7, -0.5))
```

--

All elements of a vector are the same type (e.g. numeric or character)!

If you mix character and numeric data, the resulting vector will be *character*.

---
# Element-wise Vector Math

When doing arithmetic operations on vectors, R handles these *element-wise*:
```{r}
c(1, 2, 3) + c(4, 5, 6)
c(1, 2, 3, 4)^3 # exponentiation with ^
```

Common operations: `*`, `/`, `exp()` = $e^x$, `log()` = $\log_e(x)$

---
# Vector Recycling

If we work with vectors of different lengths, R will **recycle** the shorter one by repeating it to make it match up with the longer one:
```{r}
c(0.5, 3) * c(1, 2, 3, 4)
c(0.5, 3, 0.5, 3) * c(1, 2, 3, 4) # same thing
```

---
# Scalars as Recycling

A special case of recycling involves arithmetic with **scalars** (a single number). These are vectors of length 1 that are recycled to make a longer vector:
```{r}
3 * c(-1, 0, 1, 2) + 1
```

---
# Warning on Recycling

Recycling doesn't work so well with vectors of incommensurate lengths:

```{r, warning=TRUE}
c(1, 2, 3, 4) + c(0.5, 1.5, 2.5)
```

Try not to let R's recycling behavior catch you by surprise!

---
# Vector-Wise Math

Some functions operate on an entire vector and return *one number* rather than working element-wise:

```{r}
sum(c(1, 2, 3, 4))
max(c(1, 2, 3, 4))
```

Some others: `min()`, `mean()`, `median()`, `sd()`, `var()`

You've seen these used with `dplyr::summarize()`.

---
# Example: Standardizing Data

Let's say we had some test scores and we wanted to put these on a standardized scale: 

$$z_i = \frac{x_i - \text{mean}(x)}{\text{SD}(x)}$$

--

```{r}
x <- c(97, 68, 75, 77, 69, 81, 80, 92, 50, 34, 66, 83, 62)
z <- (x - mean(x)) / sd(x)
round(z, 2)
```

The `scale()` function performs the above operation!

---
# Types of Vectors

`class()` or `str()` will tell you what kind of vector you have. There are a few common types of vectors:

--

* **numeric**: `c(1, 10*3, 4, -3.14)` <sup>1</sup>
.footnote[[1] R is perfectly happy with you including a calculation--or any other valid object--as an element!]

--

    + **integer**: `0:10`

--

* **character**: `c("red", "blue", "yellow", "blue")`

--

* **factor**: `factor(c("red", "blue", "yellow", "blue"))`

--

* **logical**: `c(FALSE, TRUE, TRUE, FALSE)`

---
# Generating Numeric Vectors

Numeric vectors contain only numbers, with any number of decimal places.

There are shortcuts for generating common kinds of vectors:
```{r}
seq(-3, 6, by = 1.75) # Sequence from -3 to 6, increments of 1.75
rep(c(-1, 0, 1), times = 3) # Repeat c(-1,0,1) 3 times
rep(c(-1, 0, 1), each = 3) # Repeat each element 3 times
```

---
# Generating Integer Vectors

Integer vectors are a special case of numeric vectors where all the values are whole numbers.

--

We can produce them using the `:` shortcut:

```{r}
n <- 12
1:n
n:4
```

--

You can also specify a single integer using a whole number followed by `L`:

```{r}
class(9L)
```

---
# Character Vectors

Character vectors store data as text and typically come up when dealing names, addresses, and IDs:

```{r}
first_names <- c("Andre", "Beth", "Carly", "Dan")
class(first_names)
```

Note you can store numbers as character data as well, but you cannot perform math on them unless you convert them to numeric.

---
# Factor Vectors

Factors are categorical data that encode a (modest) number of **levels**, like for sex, experimental group, or geographic region: 

```{r}
sex <- factor(c("M", "F", "F", "M"))
sex
```

--

Character data usually can't go directly into a statistical model<sup>1</sup>, but factor data can. It has an *underlying numeric representation*:

```{r}
as.numeric(sex)
```

.footnote[[1] Most R models will automatically convert character data to factors. The default reference is chosen alphabetically.]

---
# Logical Vectors

Logical vectors take only TRUE and FALSE values, and are typically the product of logical tests (e.g. `x==5`). We can make logical vectors by defining binary conditions to check for. For example, we can look at which of the first names has at least 4 letters:

```{r}
name_lengths <- nchar(first_names) # number of characters
name_lengths
name_lengths >= 4
```

---
# Logical Vectors as Numeric

You can do math with logical vectors, because `TRUE`=1 and `FALSE`=0:

```{r}
name_lengths >= 4
mean(name_lengths >= 4)
```

What did this last line do?

--

It told us the *proportion* of name lengths greater than or equal to four!

---
# Combining Logical Conditions

Suppose we are interested in which names have an even number of letters:

```{r}
even_length <- (name_lengths %% 2 == 0)
# %% is the modulo operator: gives remainder when dividing
even_length
```

--

or whose second letter is "a":
```{r}
second_letter_a <- (substr(first_names, start=2, stop=2) == "a")
# substr: substring (portion) of a char vector
second_letter_a
```

---
# Logical Operators

* `&` is **AND** (both conditions must be `TRUE` to be `TRUE`):

```{r}
even_length & second_letter_a
```

--

* `|` is **OR** (at least one condition must be `TRUE` to be `TRUE`):

```{r}
even_length | second_letter_a
```

--

* `!` is **NOT** (switches `TRUE` and `FALSE`):

```{r}
!(even_length | second_letter_a)
```

---
# Subsetting Vectors

We can **subset** a vector in a number of ways:

* Passing a single index or vector of entries to **keep**:

```{r}
first_names[c(1, 4)]

```

--

* Passing a single index or vector of entries to **drop**:

```{r}
first_names[-c(1, 4)]
```

---
# Subsetting Vectors

* Passing a logical vector (`TRUE`=keep, `FALSE`=drop):

```{r}
first_names[even_length | second_letter_a]
first_names[sex != "F"] # != is "not equal to"
```

---
# Some Logical/Subsetting Functions

`%in%` lets you avoid typing a lot of logical ORs (`|`):

```{r}
first_names %in% c("Andre", "Carly", "Dan")
```

--

`which()` gives the *indices* of `TRUE`s in a logical vector:

```{r}
which(first_names %in% c("Andre", "Carly", "Dan"))
```

---
# Missing Values

Missing values are coded as `NA` entries without quotes:

```{r}
vector_w_missing <- c(1, 2, NA, 4, 5, 6, NA)
```

--

Even one `NA` "poisons the well": You'll get `NA` out of your calculations unless you remove them manually or with the extra argument `na.rm = TRUE` (in some functions):

```{r}
mean(vector_w_missing)
mean(vector_w_missing, na.rm=TRUE)
```

---
# Finding Missing Values

**WARNING:** You can't test for missing values by seeing if they "equal" (`==`) `NA`:

```{r}
vector_w_missing == NA
```

--

Instead, use the `is.na()` function:

```{r}
is.na(vector_w_missing)
mean(vector_w_missing[!is.na(vector_w_missing)])
```

This is the same as using `mean(na.rm=T)`

---
# `NA` and `%in%`

When testing logical conditions, `NA` will produce an `NA` rather than `TRUE` or `FALSE`:

```{r}
vector_w_missing == 5
```

--

It is noteworthy, however, that `%in%` will handle NAs:

```{r}
vector_w_missing %in% 5
vector_w_missing %in% NA
```

It is still usually best to handle NAs *directly*, however!

---
# `Inf` and `NaN`

Sometimes we might get positive or negative infinity (`Inf`, `-Inf`) or `NaN` (**N**ot **A** **N**umber) from our calculations:

```{r}
c(-2, -1, 0, 1, 2) / 0
```

--

You can check for these using functions like `is.finite()` or `is.nan()`.<sup>1</sup>

```{r}
is.finite(c(-2, -1, 0, 1, 2) / 0)
is.nan(c(-2, -1, 0, 1, 2) / 0)
```

.footnote[[1] Infinity is a number... but isn't finite.]

---
# Previewing Vectors

Like with data frames, we can use `head()` and `tail()` to preview vectors:

```{r}
head(letters) # letters is a built-in vector
head(letters, 10)
tail(letters)
```

---
# Named Vector Entries

We can also index vectors by assigning **names** to the entries.

```{r}
a_vector <- 1:26
names(a_vector) <- LETTERS # capital version of letters #<<
head(a_vector)
a_vector[c("R", "S", "T", "U", "D", "I", "O")]
```

Names are nice for subsetting because they don't depend on your data being in a certain order.

---
class: inverse
# Matrices

---

# Matrices: Two Dimensions

**Matrices** extend vectors to two **dimension**s: **rows** and **columns**. We can construct them directly using `matrix`.

Note the `byrow=` argument which determines whether the data fill the matrix by row or by column.
```{r}
(a_matrix <- matrix(letters[1:6], nrow=2, ncol=3))
(b_matrix <- matrix(letters[1:6], nrow=2, ncol=3, byrow=TRUE))
```

---
# Binding Vectors

We can also make matrices by *binding* vectors together with `rbind()` (**r**ow **bind**) and `cbind()` (**c**olumn **bind**).

```{r}
(c_matrix <- cbind(c(1, 2), c(3, 4), c(5, 6)))
(d_matrix <- rbind(c(1, 2, 3), c(4, 5, 6)))
```

---
# Subsetting Matrices

We subset matrices using the same methods as with vectors, except we index them with `[rows, columns]`:

```{r}
a_matrix[1, 2] # row 1, column 2
a_matrix[1, c(2, 3)] # row 1, columns 2 and 3
```

--

We can obtain the dimensions of a matrix using `dim()`.

```{r}
dim(a_matrix)
```

Note that using `length()` on a matrix will not give you the number of rows or columns but rather the number of elements!

---
# Matrices Becoming Vectors

If a matrix ends up having just one row or column after subsetting, by default R will make it into a vector. You can prevent this behavior using `drop=FALSE`.

```{r}
a_matrix[, 1] # all rows, column 1, becomes a vector
a_matrix[, 1, drop=FALSE] # all rows, column 1, stays a matrix
```

---
# Matrix Data Type Warning

Matrices can be numeric, integer, factor, character, or logical, just like vectors. Also like vectors, *all elements must be the same data type*.

```{r}
(bad_matrix <- cbind(1:2, LETTERS[c(6,1)]))
typeof(bad_matrix)
```

In this case, everything was converted to character so as not to lose information.

---
# Matrix Dimension Names

We can access dimension names or name them ourselves:

```{r}
rownames(bad_matrix) <- c("Wedge", "Biggs")
colnames(bad_matrix) <- c("Pilot grade", "Mustache grade")
bad_matrix
bad_matrix["Biggs", , drop=FALSE]
```

---
# Matrix Arithmetic

Matrices of the same dimensions can have math performed entry-wise with the usual arithmetic operators:

```{r}
cbind(c_matrix, d_matrix) # look at side by side
3 * c_matrix / d_matrix
```

---
# Matrix Transposition and Multiplication

To do matrix transpositions, use `t()`.

```{r}
(e_matrix <- t(c_matrix))
```

--

To do actual matrix multiplication (not entry-wise), use `%*%`.

```{r}
(f_matrix <- d_matrix %*% e_matrix)
```

---
# Matrix Inversion

To invert an invertible square matrix, use `solve()`.

```{r}
(g_matrix <- solve(f_matrix))
f_matrix %*% g_matrix
```

Note the [floating point imprecision](https://floating-point-gui.de/basic/): The off-diagonals are *very close to zero* rather than actually zero!

---
# Diagonal Matrices

To extract the diagonal of a matrix or make a diagonal matrix (usually the identity matrix), use `diag()`.

```{r}
diag(2)
diag(g_matrix)
```

---
class: inverse
# Lists

---
# What are Lists?

**Lists** are an object that can store multiple types of data.

.small[
```{r}
(my_list <- list("first_thing"  = 1:5,
                 "second_thing" = matrix(8:11, nrow = 2),
                 "third_thing"  = lm(dist ~ speed, data = cars)))
```
]

---
# Accessing List Elements

You can access a list element by its name or number in `[[ ]]`, or a `$` followed by its name:

```{r}
my_list[["first_thing"]]
my_list$first_thing
my_list[[1]]
```

---
# Why Two Brackets `[[` `]]`?

If you use single brackets to access list elements, you get a **list** back. Double brackets get *the actual element*—as whatever data type it is stored as—in that location in the list.

```{r}
str(my_list[1])
str(my_list[[1]])
```

--

Note that you can only select a single element at a time using `[[ ]]`, because this would have to return *multiple objects*!

An R function can only return one object at a time—otherwise operations like assignment would be impossible.

---
# Subsetted Lists Can Be of Length > 1

You can use vector-style subsetting to get a sublist of multiple elements:
```{r}
length(my_list[c(1, 2)])
str(my_list[c(1, 2)])
```

---
# Regression Output is a List!

.small[
```{r, R.options=list(max.print=2)}
str(my_list[[3]], list.len=7) # Displaying on first 7 elements
```
]

---
# `names()` and List Elements

You can use `names()` to get a vector of list element names:

```{r}
names(my_list[[3]])
```

---
# Data Frames are Lists!

data frames are lists of equal-length vectors.

```{r}
str(cars)
length(cars)
length(cars$dist) # should be same as nrow(cars)
```

---
# You Can Treat Data Frames like a Matrix

```{r}
cars[1, ]
cars[1:5, "speed", drop = FALSE]
```

---
# Base R vs. `dplyr`

Two ways of calculating the same thing: which do you like better?

Classic R:
```{r, eval=FALSE}
mean(swiss[swiss$Education > mean(swiss$Education), "Education"])
```

--

`dplyr`:
```{r, eval=FALSE}
library(dplyr)
swiss %>%
    filter(Education > mean(Education)) %>%
    summarize(mean = mean(Education))
```

---
# Tibbles

.smallish[
`tidyverse` functions often use a type of data frame called a *tibble*. You can create them manually with `tibble()` as with `data.frame()` or convert existing data frames into tibbles using `as_tibble()`. Tibbles display better than data frames: they truncate output and include column types. They also do not convert strings to factors!

Because the `tidyverse` has abolished row names, `tibbles()` have none. You can convert row names to columns using `tibble::rownames_to_column()` or with the `rownames=` argument in `as_tibble()`.
]

.small[
.pull-left[
```{r}
swiss %>% select(2:3) %>% head()
```
]
.pull-right[
```{r}
swiss %>% select(2:3) %>% 
  as_tibble(rownames="Name") %>% head()
```
]
]



---
class: inverse
# An Aside

## for People with Statistics Training

---
# Getting Fitted Regression Coefficients

Recall that `my_list[[3]]` is output from a regression model.

```{r}
my_list[[3]][["coefficients"]]
(speed_beta <- my_list[[3]][["coefficients"]]["speed"])
```

---
# Regression Summaries

`summary(lm_object)` is also a list with more information, which has the side effect of printing some output to the console:

.small[
```{r}
summary(my_list[[3]]) # this prints output
```
]

---
# Getting Standard Errors

.smallish[
```{r}
summary(my_list[[3]])[["coefficients"]] # a matrix
(speed_SE <- summary(my_list[[3]])[["coefficients"]]["speed", "Std. Error"])
```
]

---
# Example: 95% confidence interval

```{r}
speed_CI <- speed_beta + c(-qnorm(0.975), qnorm(0.975)) * speed_SE #<<
names(speed_CI) <- c("lower", "upper")
```
.footnote[ `qnorm(0.975)` is `r round(qnorm(0.975),2)`]

--

Now you can include these values in a Markdown document:

```{r, eval=FALSE}
A 1 mph increase in speed is associated with a `r 
round(speed_beta, 1)` ft increase in stopping distance 
(95% CI: (`r round(speed_CI["lower"],1)`,
          `r round(speed_CI["upper"],1)`)).
```

A 1 mph increase in speed is associated with a `r round(speed_beta, 1)` ft increase in stopping distance (95% CI: (`r round(speed_CI["lower"],1)`, `r round(speed_CI["upper"],1)`)).

---
class: inverse
# Practice and Homework

---
# Suggested Practice: `swirl`

You can do interactive R tutorials in `swirl` that cover these structure basics. To set up `swirl`:

1. `install.packages("swirl")`
2. `library(swirl)`
3. `swirl()`
4. Choose `R Programming`, pick a tutorial, and follow directions
5. To get out of `swirl`, type `bye()` in the middle of a lesson, or `0` in the menus

At this point, tutorials 1-8 are appropriate.

---
class: inverse
# Homework: Two Choices

### Data Structure Practice (Less Advanced):
Fill in a template R Markdown file that walks you through 
creating, accessing, and manipulating R data structures. Enter values in 
the R Markdown document and knit it to check your answers. *Knit after entering each answer*. 
If you get an error, check to see if undoing your last edit solves the problem; coding an assignment to handle
all possible mistakes is really hard! This assignment is also long, so *start early*.

### Manual Linear Regression (More Advanced)
Fill in a template R markdown file that walks you through (1) doing linear regression
manually and (2) comparing it to the built-in `lm()` function. Includes simulating data and
creating and modifying data structures. *Knit after entering each answer*. This
assignment does not check answers as you go. This is also long, so *start early*!